---
title: "Data Center Apprenticeship:<br>Working with external data"
date: "Spring 2024<br>Last updated: `r Sys.Date()`"
output: 
  html_document:
    theme: cosmo
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = FALSE)
```

*Schedule:*

* any unfinished data wrangling
* ~1 hour: import/export
* ~1 hour: combining data
* anything else to add here?

# Introduction

This tutorial covers how to work with various types of external data in R.
First we cover how to import and export from and to various file formats, and discuss a number of available packages to do so.
Then you'll also learn multiple ways of combining data from different sources into a single tibble.

# Importing and exporting different file formats

**source: https://ucrdatacenter.github.io/tutorial/r_data.html - fix broken link at bottom of page**

Start by reading the introduction to importing the most common file types (text files, Excel, SPSS, Stata) [here](https://ucrdatacenter.github.io/tutorial/r_data.html).
It is good to be aware of the Import dataset button and use it when needed, but in the long run it is easier to be aware of the available import functions and use them directly.

The following gives more information and examples of importing data from different file formats and different levels of tidiness.

## Packages

We will use the following packages for importing different file formats:

```{r}
library(tidyverse)
library(readxl) # for Excel
library(haven) # for SPSS, Stata, SAS
library(jsonlite) # for JSON
library(arrow) # for parquet, big data
```

The `rio` package provides a generic import function, however, it is simply a wrapper for many of the other import functions shown below.
While it may be easier to use the same import function for many file formats, `rio` redirects you to the original functions if you look for the possible function arguments.
In some cases, `rio` can read URL file paths that `readr` (the `tidyverse` package for data import) can't.

## Examples

First, download [this](https://github.com/ucrdatacenter/projects/tree/main/apprenticeship/2_data) zip-file from GitHub, and extract it into a data folder within your apprenticeship project directory.
We now import each file, explaining the packages, functions, and function arguments used.

`student_male.csv` is a comma-separated text file.
Opening it in a notepad or Excel shows that the column separators are semicolons (;).
The `read_csv()` function from the previous workshop expects commas as a separator, while `read_csv()` expects semicolons.
Since CSV files are a form of delimited text files, we can also use the more versatile `read_delim()` function specifying the delimiter as the argument.

```{r, eval = FALSE}
student_male <- read_csv2("data/student_male.csv")
student_male <- read_delim("data/student_male.csv", delim = ";")
```

`student_female.tab` is also a delimited text file.
Opening it in a notepad shows that the delimiter is a tab.
The notation for tab whitespace is `\t`, which we can specify in the `delim` argument.
Like the ".tab" file extension, ".tsv" is also a tab-separated text file, so the more specialized `read_tsv()` function also works.

```{r}
student_female <- read_delim("data/student_female.tab", delim = "\t")
student_female <- read_tsv("data/student_female.tab")
```

To import Excel file we need the `read_excel()` function from the `read_excel()` package.
With this function you can specify which sheet to use in addition to similar arguments as for delimited text files.

```{r}
student_char_sports <- read_excel("data/student_char_sports.xlsx")
```

The `haven` package reads files in the data formats of Stata (.dta) and SPSS (.sav).

```{r}
student_char1_A <- read_dta("data/student_char1_A.dta")
```

```{r}
student_char2_A <- read_sav("data/student_char2_A.sav")
```

RDS is an R-specific file format that saves all attributes of the dataframe as well (e.g. grouping, factor levels).
It is particularly useful for saving intermediate data files, e.g. saving the cleaned data before analysis to avoid needing to run the data cleaning script repeatedly.

```{r}
student_age_grades_working <- read_rds("data/student_age_grades_working.rds")
```

JSON

```{r}
student_grades <- fromJSON("data/student_grades.json")
```

parquet

```{r}
student_more_id_age <- open_dataset("data/student_more_id_age")
```

## Exporting data

To export data from R, you can almost always use the `write_...()` function corresponding to the desired file format, e.g. `write_csv()` or `write_dta`.
For Excel files the preferred export function is `read_xlsx()`.
For other file format the generic `write()` function is useful; you can specify any file format, and if your input data is readable in the chosen format, the file will export properly.
In all these `write_()` functions you need to specify the data you'd like to save (often in a pipe workflow) and the output file path including chosen file extension, with the exception of `write_dataset()` from `arrow`, where you specify the path to be a (new) folder, and you add a separate `format = "parquet"` argument.
For example:

```{r, eval = FALSE}
write_xlsx(student_male, "data/new_csv_data.csv")

student_female |> 
  write_dataset("data/new_parquet_data", format = "parquet")
```

A few notes regarding importing and exporting data:

* Always make sure you know your current working directory and the relative path to your data directory. It is better to use relative rather than absolute file paths (i.e. `data/data.csv` instead of `C:/User/Project/data/data.csv`).
* Note that if you are using Windows, you may need to replace the backslashes (\\) in the file path with forward slashes (/) to avoid errors.
* You can import files directly from URLs, although you often need the URL of a raw file. On Github you can access the URL of raw CSV files by clicking on the "Raw" button on the data preview page (see e.g. [here](https://github.com/ucrdatacenter/projects/blob/main/apprenticeship/1_intro/surveys.csv)). If a file downloads immediately instead of opening in a raw format, you can try to copy that download link by right-clicking and selecting "Copy link address"; the `import()` function from `rio` might be successful with those links.

add info on:

* available options: file formats, delimiters, skip, column types, column names  

# Combining dataframes

## Row and column binding

* example cases where bind_rows() and bind_cols() are useful
* mention that for matrices corresponding functions are rbind(), cbind(), for vectors and lists c()

<!-- One of the common tasks in data analysis is to combine different data sets into a single one. This can be done by either binding rows or columns of two or more data frames. The tidyverse package provides two functions for this purpose: bind_rows() and bind_cols(). These functions are similar to the base R functions rbind() and cbind(), but they have some advantages, such as preserving column names and types, and handling missing values. For matrices, rbind() and cbind() are still the preferred options, and for vectors and lists, the c() function can be used to concatenate them. -->


## Joins

* examples of when each join is useful
* animations of joins: https://www.garrickadenbuie.com/project/tidyexplain/#mutating-joins
* syntax of by argument

<!-- Mutating joins are a type of join operation that add columns from one data frame to another, based on matching values of some variables. They are useful when you want to combine information from different sources without losing observations or duplicating rows. In R, you can use the dplyr package from the tidyverse to perform mutating joins with a consistent syntax. -->

<!-- There are four types of mutating joins: inner join, left join, right join, and full join. Each one has a different behavior when there are unmatched rows in either data frame. Here is a brief summary of each join: -->

<!-- - inner_join(x, y) keeps only the rows in x that have a matching value in y. It is the most restrictive type of join, and it can result in data loss if there are unmatched rows. -->
<!-- - left_join(x, y) keeps all the rows in x, and adds columns from y if there is a match. If there is no match, it fills the new columns with NA values. It is useful when you want to preserve the original data frame and augment it with additional information. -->
<!-- - right_join(x, y) keeps all the rows in y, and adds columns from x if there is a match. If there is no match, it fills the new columns with NA values. It is useful when you want to use the second data frame as the reference and add information from the first one. -->
<!-- - full_join(x, y) keeps all the rows in x or y, and adds columns from both data frames if there is a match. If there is no match, it fills the new columns with NA values. It is useful when you want to include all possible combinations of values from both data frames. -->

<!-- To perform a mutating join, you need to specify which variables to use as the keys for matching. You can do this in two ways: -->

<!-- - If the variables have the same name in both data frames, you can use by = "variable" or by = c("var1", "var2", ...) to list them. -->
<!-- - If the variables have different names in each data frame, you can use by = join_by(x_var == y_var) or by = join_by(x_var1 == y_var1, x_var2 == y_var2, ...) to create an equality expression for each pair of variables. -->
